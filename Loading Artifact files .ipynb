{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas for data manipulation\n",
    "#os for reading available files in a folder\n",
    "#numpy for computaion\n",
    "#sklearn- traintest split for splitting the data\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#os.listdir lists all files in the given directry\n",
    "files=os.listdir(\"Artifacts tagged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfs=data frames of all files with 1st second trimmed as it containd random values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv('Artifacts tagged/'+fp,names=['amplitude','value'])[250:] for fp in files]\n",
    "#concat funtion joins all files in dfs and make a large df(data frame)\n",
    "df = pd.concat(dfs)\n",
    "#reset_index resets the index from 1 2 3....7 8 1 2 3     to         1 2 3 ... 7 8 9 10 11\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arr is a 2d array like [[(amplitude values)321,32,4,43],(label)45] containing labled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr initialized\n",
    "arr=[]\n",
    "#loop\n",
    "while(True):\n",
    "    #find first non 0 value\n",
    "    start=df.value.ne(0).idxmax()\n",
    "    #end condition\n",
    "    if(start==0):\n",
    "        break\n",
    "    # create a temp variable to store df excluding starting zeros\n",
    "    temp=df.iloc[start:]\n",
    "    #from temp finding first zero\n",
    "    end=temp[temp.value==0].first_valid_index()-1\n",
    "    #a contains the latest chunk of labled data\n",
    "    a=df.iloc[start:end]\n",
    "    a=a.reset_index(drop=True)\n",
    "    #appending a to arr\n",
    "    arr.append([a.amplitude.tolist(),a.value[0]])\n",
    "    #truncate the original df to first found chunk\n",
    "    df=df.iloc[end+1:]\n",
    "    df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting arr to numpy array for computaion \n",
    "arr=np.array(arr)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n"
     ]
    }
   ],
   "source": [
    "#data_points contain the number of thunks created\n",
    "data_points=arr.shape[0]\n",
    "print(data_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# as real eeg chunks are too large i size we need to cut them into randon chunks and add again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 6 rows of arr contained read eeg data so inserting it into realEEG variable\n",
    "realEEG=[]\n",
    "for i in range(1,7):\n",
    "    realEEG.append(arr[-i])\n",
    "realEEG=np.array(realEEG)\n",
    "\n",
    "realEEG.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# truncate last 6 rows from arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=arr[0:data_points-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deviding realEEG files to smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (306,)\n",
      "a (167,)\n",
      "a (340,)\n",
      "a (149,)\n",
      "a (329,)\n",
      "a (197,)\n",
      "a (224,)\n",
      "a (133,)\n",
      "a (315,)\n",
      "a (125,)\n",
      "a (148,)\n",
      "a (109,)\n",
      "a (251,)\n",
      "a (137,)\n",
      "a (302,)\n",
      "a (101,)\n",
      "a (179,)\n",
      "a (317,)\n",
      "a (139,)\n",
      "a (212,)\n",
      "a (276,)\n",
      "a (239,)\n",
      "a (295,)\n",
      "a (184,)\n",
      "a (354,)\n",
      "a (345,)\n",
      "s\n",
      "(256,)\n",
      "(27, 2)\n",
      "(359, 2)\n",
      "a (119,)\n",
      "a (227,)\n",
      "a (121,)\n",
      "a (317,)\n",
      "a (173,)\n",
      "a (200,)\n",
      "a (134,)\n",
      "a (192,)\n",
      "a (199,)\n",
      "a (396,)\n",
      "a (389,)\n",
      "a (318,)\n",
      "a (345,)\n",
      "a (290,)\n",
      "a (332,)\n",
      "a (320,)\n",
      "a (225,)\n",
      "a (390,)\n",
      "a (392,)\n",
      "a (222,)\n",
      "a (313,)\n",
      "d\n",
      "(21, 2)\n",
      "(380, 2)\n",
      "a (287,)\n",
      "a (162,)\n",
      "a (284,)\n",
      "a (179,)\n",
      "a (283,)\n",
      "a (304,)\n",
      "a (305,)\n",
      "a (240,)\n",
      "a (332,)\n",
      "a (212,)\n",
      "a (152,)\n",
      "a (120,)\n",
      "a (295,)\n",
      "a (354,)\n",
      "a (214,)\n",
      "a (315,)\n",
      "a (237,)\n",
      "a (349,)\n",
      "a (274,)\n",
      "a (165,)\n",
      "a (119,)\n",
      "a (292,)\n",
      "a (215,)\n",
      "a (391,)\n",
      "a (357,)\n",
      "s\n",
      "(131,)\n",
      "(26, 2)\n",
      "(406, 2)\n",
      "a (295,)\n",
      "a (318,)\n",
      "a (177,)\n",
      "a (161,)\n",
      "a (268,)\n",
      "a (350,)\n",
      "a (357,)\n",
      "a (249,)\n",
      "s\n",
      "(312,)\n",
      "(9, 2)\n",
      "(415, 2)\n",
      "a (139,)\n",
      "a (148,)\n",
      "a (287,)\n",
      "a (147,)\n",
      "a (281,)\n",
      "a (189,)\n",
      "a (163,)\n",
      "a (396,)\n",
      "a (162,)\n",
      "a (202,)\n",
      "a (230,)\n",
      "a (245,)\n",
      "a (275,)\n",
      "a (280,)\n",
      "a (292,)\n",
      "a (188,)\n",
      "a (353,)\n",
      "a (361,)\n",
      "a (355,)\n",
      "s\n",
      "(157,)\n",
      "(20, 2)\n",
      "(435, 2)\n",
      "a (393,)\n",
      "a (327,)\n",
      "a (184,)\n",
      "a (241,)\n",
      "a (387,)\n",
      "d\n",
      "(5, 2)\n",
      "(440, 2)\n"
     ]
    }
   ],
   "source": [
    "#loop through the files and append into arr\n",
    "for _ in range(6):\n",
    "    a=realEEG[_]\n",
    "    temp=[]\n",
    "    i=0\n",
    "    l=len(a[0])\n",
    "    #loop through and append into temp\n",
    "    while(i<l):\n",
    "        #generating a random number from 100-400 (size of other files)\n",
    "        ran=random.randrange(100, 400)\n",
    "        #corner cases for last left chunks in files\n",
    "        if(l-i<100):\n",
    "            print('d')\n",
    "            break\n",
    "        if(l-i<400):\n",
    "            print('s')\n",
    "            temp.append([a[0][i:l],float(79.0)])\n",
    "            print(np.array(a[0][i:l]).shape)\n",
    "            break\n",
    "        #appending to temp\n",
    "        print('a',end=' ')\n",
    "        print(np.array(a[0][i:i+ran]).shape)\n",
    "        temp.append([a[0][i:i+ran],float(79.0)])\n",
    "        i+=ran\n",
    "    temp=np.array(temp)\n",
    "    print(temp.shape)\n",
    "    #appending to arr\n",
    "    arr=np.concatenate((arr,temp))\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 332 artifacts aprox 108 real EEG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting array to a df for formatting\n",
    "df=pd.DataFrame(arr,columns=['X','Y'])\n",
    "# Extracting X, Y\n",
    "X=df.X.values\n",
    "Y=df.Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "87\n",
      "121\n",
      "106\n",
      "100\n",
      "102\n",
      "95\n",
      "65\n",
      "48\n",
      "68\n",
      "74\n",
      "49\n",
      "55\n",
      "116\n",
      "206\n",
      "269\n",
      "241\n",
      "246\n",
      "220\n",
      "239\n",
      "264\n",
      "197\n",
      "186\n",
      "274\n",
      "270\n",
      "275\n",
      "273\n",
      "222\n",
      "194\n",
      "239\n",
      "195\n",
      "213\n",
      "188\n",
      "228\n",
      "232\n",
      "245\n",
      "270\n",
      "279\n",
      "249\n",
      "162\n",
      "100\n",
      "165\n",
      "168\n",
      "235\n",
      "174\n",
      "212\n",
      "188\n",
      "224\n",
      "229\n",
      "258\n",
      "196\n",
      "184\n",
      "188\n",
      "197\n",
      "141\n",
      "264\n",
      "196\n",
      "176\n",
      "160\n",
      "282\n",
      "181\n",
      "217\n",
      "192\n",
      "152\n",
      "200\n",
      "233\n",
      "257\n",
      "203\n",
      "223\n",
      "234\n",
      "223\n",
      "232\n",
      "228\n",
      "226\n",
      "349\n",
      "361\n",
      "319\n",
      "215\n",
      "234\n",
      "226\n",
      "229\n",
      "211\n",
      "290\n",
      "202\n",
      "232\n",
      "171\n",
      "162\n",
      "301\n",
      "276\n",
      "347\n",
      "391\n",
      "397\n",
      "402\n",
      "179\n",
      "255\n",
      "158\n",
      "131\n",
      "69\n",
      "66\n",
      "130\n",
      "185\n",
      "102\n",
      "46\n",
      "181\n",
      "171\n",
      "121\n",
      "155\n",
      "155\n",
      "122\n",
      "142\n",
      "185\n",
      "161\n",
      "154\n",
      "175\n",
      "159\n",
      "162\n",
      "174\n",
      "97\n",
      "148\n",
      "131\n",
      "164\n",
      "197\n",
      "180\n",
      "76\n",
      "66\n",
      "179\n",
      "164\n",
      "170\n",
      "191\n",
      "210\n",
      "130\n",
      "26\n",
      "74\n",
      "145\n",
      "170\n",
      "212\n",
      "41\n",
      "207\n",
      "97\n",
      "151\n",
      "139\n",
      "149\n",
      "120\n",
      "60\n",
      "93\n",
      "87\n",
      "47\n",
      "72\n",
      "135\n",
      "121\n",
      "55\n",
      "108\n",
      "111\n",
      "94\n",
      "92\n",
      "155\n",
      "65\n",
      "28\n",
      "24\n",
      "103\n",
      "129\n",
      "199\n",
      "157\n",
      "94\n",
      "68\n",
      "129\n",
      "46\n",
      "42\n",
      "175\n",
      "129\n",
      "108\n",
      "119\n",
      "43\n",
      "64\n",
      "268\n",
      "245\n",
      "203\n",
      "139\n",
      "203\n",
      "225\n",
      "283\n",
      "302\n",
      "139\n",
      "176\n",
      "176\n",
      "159\n",
      "162\n",
      "195\n",
      "134\n",
      "264\n",
      "193\n",
      "171\n",
      "142\n",
      "133\n",
      "179\n",
      "182\n",
      "159\n",
      "103\n",
      "139\n",
      "266\n",
      "195\n",
      "270\n",
      "223\n",
      "197\n",
      "188\n",
      "200\n",
      "229\n",
      "169\n",
      "183\n",
      "154\n",
      "193\n",
      "192\n",
      "224\n",
      "196\n",
      "153\n",
      "176\n",
      "168\n",
      "158\n",
      "162\n",
      "197\n",
      "183\n",
      "125\n",
      "141\n",
      "128\n",
      "168\n",
      "179\n",
      "157\n",
      "149\n",
      "140\n",
      "154\n",
      "165\n",
      "165\n",
      "203\n",
      "182\n",
      "354\n",
      "167\n",
      "211\n",
      "258\n",
      "205\n",
      "222\n",
      "223\n",
      "153\n",
      "174\n",
      "156\n",
      "246\n",
      "188\n",
      "172\n",
      "144\n",
      "144\n",
      "188\n",
      "218\n",
      "203\n",
      "202\n",
      "206\n",
      "232\n",
      "264\n",
      "249\n",
      "264\n",
      "256\n",
      "299\n",
      "308\n",
      "189\n",
      "130\n",
      "292\n",
      "269\n",
      "231\n",
      "228\n",
      "103\n",
      "104\n",
      "113\n",
      "120\n",
      "64\n",
      "154\n",
      "168\n",
      "202\n",
      "220\n",
      "153\n",
      "191\n",
      "208\n",
      "202\n",
      "241\n",
      "220\n",
      "208\n",
      "202\n",
      "206\n",
      "190\n",
      "147\n",
      "163\n",
      "92\n",
      "184\n",
      "164\n",
      "218\n",
      "197\n",
      "170\n",
      "162\n",
      "213\n",
      "197\n",
      "162\n",
      "187\n",
      "205\n",
      "196\n",
      "162\n",
      "180\n",
      "331\n",
      "614\n",
      "395\n",
      "139\n",
      "232\n",
      "294\n",
      "230\n",
      "284\n",
      "246\n",
      "346\n",
      "229\n",
      "162\n",
      "162\n",
      "214\n",
      "246\n",
      "229\n",
      "293\n",
      "230\n",
      "246\n",
      "317\n",
      "263\n",
      "230\n",
      "212\n",
      "313\n",
      "222\n",
      "230\n",
      "198\n",
      "231\n",
      "197\n",
      "306\n",
      "167\n",
      "340\n",
      "149\n",
      "329\n",
      "197\n",
      "224\n",
      "133\n",
      "315\n",
      "125\n",
      "148\n",
      "109\n",
      "251\n",
      "137\n",
      "302\n",
      "101\n",
      "179\n",
      "317\n",
      "139\n",
      "212\n",
      "276\n",
      "239\n",
      "295\n",
      "184\n",
      "354\n",
      "345\n",
      "256\n",
      "119\n",
      "227\n",
      "121\n",
      "317\n",
      "173\n",
      "200\n",
      "134\n",
      "192\n",
      "199\n",
      "396\n",
      "389\n",
      "318\n",
      "345\n",
      "290\n",
      "332\n",
      "320\n",
      "225\n",
      "390\n",
      "392\n",
      "222\n",
      "313\n",
      "287\n",
      "162\n",
      "284\n",
      "179\n",
      "283\n",
      "304\n",
      "305\n",
      "240\n",
      "332\n",
      "212\n",
      "152\n",
      "120\n",
      "295\n",
      "354\n",
      "214\n",
      "315\n",
      "237\n",
      "349\n",
      "274\n",
      "165\n",
      "119\n",
      "292\n",
      "215\n",
      "391\n",
      "357\n",
      "131\n",
      "295\n",
      "318\n",
      "177\n",
      "161\n",
      "268\n",
      "350\n",
      "357\n",
      "249\n",
      "312\n",
      "139\n",
      "148\n",
      "287\n",
      "147\n",
      "281\n",
      "189\n",
      "163\n",
      "396\n",
      "162\n",
      "202\n",
      "230\n",
      "245\n",
      "275\n",
      "280\n",
      "292\n",
      "188\n",
      "353\n",
      "361\n",
      "355\n",
      "157\n",
      "393\n",
      "327\n",
      "184\n",
      "241\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "#d is a temp variable will be replaced by X later\n",
    "d=[]\n",
    "data_points=X.shape[0]\n",
    "for i in range(data_points):\n",
    "    temp=np.array(X[i])\n",
    "    #converting string to floats\n",
    "    temp=temp.astype(np.float)\n",
    "    \n",
    "    rows=temp.shape[0]\n",
    "    #number of valued in each chunk\n",
    "    print(rows)\n",
    "    #reshaping\n",
    "    temp=temp.reshape(rows,1)\n",
    "    #appending to d\n",
    "    d.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to numpy array\n",
    "d=np.array(d)\n",
    "X=d\n",
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean subtraction\n",
    "for i in range(X.shape[0]):\n",
    "    X[i]=X[i]-np.mean(X[i])\n",
    "    #print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty data frame\n",
    "df=pd.DataFrame(columns=['min','max','max-min','sd'])\n",
    "for i in range(X.shape[0]):\n",
    "    mini=np.min(X[i])\n",
    "    maxi=np.max(X[i])\n",
    "    sd=np.std(X[i])\n",
    "    df = df.append({'min': mini,'max':maxi,'max-min':maxi-mini,'sd':sd}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to np.ndarray\n",
    "X=df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all other except real eeg to 1\n",
    "Y[Y!=79]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146,)\n"
     ]
    }
   ],
   "source": [
    "#conveting values in y to int\n",
    "Y=Y.astype(int)\n",
    "#train test split test_size is the ratio of test sixe vs total\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#fitting X_train,y_train to classifier and storing the learned values to clf\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "#score on X_test\n",
    "clf.score(X_test,y_test)\n",
    "#storing values in y_pre\n",
    "y_pre=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[115   2]\n",
      " [  3  26]]\n",
      "Accuracy Score : 0.9657534246575342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.98      0.98       117\n",
      "          79       0.93      0.90      0.91        29\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       146\n",
      "   macro avg       0.95      0.94      0.95       146\n",
      "weighted avg       0.97      0.97      0.97       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#detailed results\n",
    "actual=y_test\n",
    "predicted=y_pre\n",
    "results = confusion_matrix(actual, predicted) \n",
    "print ('Confusion Matrix :')\n",
    "print(results) \n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted) )\n",
    "#print ('Report : ')\n",
    "print (classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#defining the classifier\n",
    "clf = SVC(kernel='linear') \n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pre=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[117   0]\n",
      " [  1  28]]\n",
      "Accuracy Score : 0.9931506849315068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       117\n",
      "          79       1.00      0.97      0.98        29\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       146\n",
      "   macro avg       1.00      0.98      0.99       146\n",
      "weighted avg       0.99      0.99      0.99       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual=y_test\n",
    "predicted=y_pre\n",
    "results = confusion_matrix(actual, predicted) \n",
    "print ('Confusion Matrix :')\n",
    "print(results) \n",
    "print ('Accuracy Score :',accuracy_score(actual, predicted) )\n",
    "#print ('Report : ')\n",
    "print (classification_report(actual, predicted) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931506849315068"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "knn.score(X_test,y_test)\n",
    "#y_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
